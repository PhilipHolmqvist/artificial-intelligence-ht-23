{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "983bdc6e",
      "metadata": {
        "id": "983bdc6e"
      },
      "source": [
        "# ID3 implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75b6ed70",
      "metadata": {
        "id": "75b6ed70"
      },
      "outputs": [],
      "source": [
        "# Some required imports.\n",
        "# Make sure you have these packages installed on your system.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d22d390",
      "metadata": {
        "id": "7d22d390"
      },
      "outputs": [],
      "source": [
        "# Some functions needed when creating the decision tree\n",
        "class Utils:\n",
        "\n",
        "    #Calculates the entropy for the values in target_column, which should be of type Pandas.DataFrame\n",
        "    @staticmethod\n",
        "    def entropy(target_column):\n",
        "\n",
        "        num_instances_all_classes = len(target_column)\n",
        "\n",
        "        value_counts = target_column.value_counts()\n",
        "\n",
        "        entropy = 0\n",
        "\n",
        "        for target_value in value_counts.keys():\n",
        "            num_instances_current_class = value_counts[target_value[0]]\n",
        "            share_instances_current_class = num_instances_current_class/num_instances_all_classes\n",
        "            entropy = entropy - share_instances_current_class * math.log2(share_instances_current_class)\n",
        "\n",
        "        return entropy\n",
        "\n",
        "    # Identifies the dominating class for the entries in target_column\n",
        "    # target_column should be of typePandas.DataFrame\n",
        "    @staticmethod\n",
        "    def find_dominating_class(target_column):\n",
        "\n",
        "        return_class = None\n",
        "        count_return_class = 0\n",
        "\n",
        "        value_counts = target_column.value_counts()\n",
        "        for target_value in value_counts.keys():\n",
        "            if value_counts[target_value[0]] > count_return_class:\n",
        "                count_return_class = value_counts[target_value[0]]\n",
        "                return_class = target_value\n",
        "\n",
        "        return return_class\n",
        "\n",
        "    # This method returns a unique node identifier\n",
        "    @staticmethod\n",
        "    def get_next_node_id():\n",
        "        global node_id_counter\n",
        "        node_id = node_id_counter\n",
        "        node_id_counter = node_id_counter + 1\n",
        "\n",
        "        return node_id\n",
        "\n",
        "    # Resets the global variable node_counter_id used to assign unique identifiers for the nodes.\n",
        "    @staticmethod\n",
        "    def reset_node_id_counter():\n",
        "        global node_id_counter\n",
        "        node_id_counter = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fd4cac8",
      "metadata": {
        "id": "3fd4cac8"
      },
      "outputs": [],
      "source": [
        "# This class is used to represent a node in the decision tree.\n",
        "class Node:\n",
        "\n",
        "    #Constructor for the node class taking the following parameters.\n",
        "    def __init__(self, height, max_height, input_columns, target_column, parent, parent_split_value):\n",
        "\n",
        "        # Height in the tree for the current node.\n",
        "        # It is suggested that the height of the root of the tree is 1.\n",
        "        self.height = height\n",
        "\n",
        "        # The maximum height of the decision tree, meaning that no path from the root\n",
        "        # to a leaf should contain more than 3 nodes.\n",
        "        self.max_height = max_height\n",
        "\n",
        "        # Pandas columns containing the input features.\n",
        "        # One column for each input feature, and each row is data point (or instance)\n",
        "        self.input_columns = input_columns\n",
        "\n",
        "        # Pandas column containing the target variable.\n",
        "        # Each row in this column contains the target value corresponding to the same row in self.input_columns\n",
        "        self.target_column = target_column\n",
        "\n",
        "        # The variable to split on in this node.\n",
        "        # For leaf nodes this is not set.\n",
        "        self.split_variable = None\n",
        "\n",
        "        # The names of the input features\n",
        "        self.input_names = self.input_columns.keys()\n",
        "\n",
        "        # The name of the target variable\n",
        "        self.target_name = self.target_column.keys()[0]\n",
        "\n",
        "        # Reference to the parent of this node.\n",
        "        # This is None for the root of the tree\n",
        "        self.parent = parent\n",
        "\n",
        "        # The class for this node if it is a leaf node.\n",
        "        # This is left empty for non leaf nodes.\n",
        "        self.class_name = None\n",
        "\n",
        "        # The unique id of this node. Used when printing the tree.\n",
        "        self.id = Utils.get_next_node_id()\n",
        "\n",
        "        # Dictionary used to keep track of the child nodes. Empty if the node is a leaf.\n",
        "        self.children = {}\n",
        "\n",
        "\n",
        "\n",
        "    # Method is used to expand a node when constucting the decision tree\n",
        "    def split(self):\n",
        "\n",
        "      scores = {}\n",
        "\n",
        "      # Calulate the information gain for each attribute in the dataset.\n",
        "      for column in self.input_columns.columns:\n",
        "        values = self.input_columns[column]\n",
        "        score = Utils.entropy(pd.DataFrame(values, columns=[column]))\n",
        "        scores[column] = score\n",
        "\n",
        "        #print(\"SCORE for {}: {}\".format(column, score))\n",
        "\n",
        "      # Find the column with the highest score, this attribute will be the root node of the decision tree.\n",
        "      highest_score_column = max(scores, key=scores.get)\n",
        "      highest_score = scores[highest_score_column]\n",
        "      #print(\"Column with highest score: {}, Score: {}\".format(highest_score_column, highest_score))\n",
        "\n",
        "      #Set the split variable to the one with the highest gain. Outlook in the first case.\n",
        "      self.split_variable = highest_score_column\n",
        "\n",
        "      #Create child nodes for each of the unique values found in the column. For outlook this would be rainy, overcast and sunny\n",
        "      unique_values = set(self.input_columns[highest_score_column])\n",
        "      for value in unique_values:\n",
        "        child_input_columns = self.input_columns[self.input_columns[highest_score_column] == value]\n",
        "        child_target_column = self.target_column.loc[child_input_columns.index]\n",
        "\n",
        "        child_node = Node(\n",
        "            height = self.height + 1,     # Add one to the height\n",
        "            max_height = self.max_height, # Keep the max height\n",
        "            input_columns = child_input_columns,\n",
        "            target_column = child_target_column,\n",
        "            parent = self, # Current node is the parent.\n",
        "            parent_split_value = value\n",
        "        )\n",
        "\n",
        "        self.children[value] = child_node\n",
        "\n",
        "        # Recursively call split on child nodes\n",
        "        if child_node.height < self.max_height:\n",
        "            child_node.split()\n",
        "        else:\n",
        "            # If height is reached set node to leaf.\n",
        "            child_node.class_name = Utils.find_dominating_class(child_node.target_column)\n",
        "\n",
        "\n",
        "    # This method creates a text representation of the decision tree.\n",
        "    def print(self):\n",
        "        print(\"Node<\" + str(self.id) + \">\" )\n",
        "\n",
        "        if not self.children:\n",
        "            print(\"  Leaf node - Parent: \", str(self.parent.id), \", Decision: \", self.class_name)\n",
        "\n",
        "        else:\n",
        "            if self.parent is None:\n",
        "                print(\"  Non leaf node - Parent: None\")\n",
        "            else:\n",
        "                print(\"  Non leaf node - Parent: \" + str(self.parent.id))\n",
        "            print(\"  Split variable: \" + self.split_variable)\n",
        "\n",
        "\n",
        "            for child_split_value in self.children.keys():\n",
        "                child_node = self.children[child_split_value]\n",
        "                print(\"    Child_node: \" + str(child_node.id) + \", split_value: \" + str(child_split_value))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea06c76",
      "metadata": {
        "id": "dea06c76"
      },
      "outputs": [],
      "source": [
        "#Class used to represent our decision tree generated using the ID3 algorithm\n",
        "\n",
        "class DecisionTree:\n",
        "\n",
        "    # Constructor that takes three input variables:\n",
        "    #   max_height - The maximum height of the decision tree.\n",
        "    #   instances - Pandas DataFrame respresenting instance vectors (both input and target)\n",
        "    #   target_name - Name of the target column.\n",
        "    def __init__(self, max_height, instances, target_name):\n",
        "\n",
        "        # Reset the global node_id_counter variable to make sure the root node gets id 1\n",
        "        Utils.reset_node_id_counter()\n",
        "\n",
        "        self.max_height = max_height;\n",
        "\n",
        "        # Create pandas dataframe containing only the target column.\n",
        "        self.target_column = instances[[target_name]]\n",
        "\n",
        "\n",
        "        if self.target_column[target_name].unique().size != 2:\n",
        "            print(\"Error: Only binary target variables are supported\")\n",
        "            exit()\n",
        "\n",
        "        # Create pandas dataframe containing all input feature columns.\n",
        "        self.input_columns = instances.drop([target_name], axis=1)\n",
        "\n",
        "        node_id_counter = 1\n",
        "\n",
        "        # Create the root of the tree\n",
        "        self.root = Node(1, self.max_height, self.input_columns, self.target_column, None, None)\n",
        "\n",
        "        # Generate the decision tree by calling the self.generate() function.\n",
        "        self.generate()\n",
        "\n",
        "    # This method is used to generate a decision tree using the ID3 algorithm\n",
        "    # All tree nodes are generated recursively when adding new nodes.\n",
        "    def generate(self):\n",
        "        self.root.split()\n",
        "\n",
        "    # Method to predict the target value for a given set of input features.\n",
        "    def predict(self, values):\n",
        "        current_node = self.root\n",
        "\n",
        "        while current_node.children:\n",
        "            split_value = values[current_node.split_variable]\n",
        "            if split_value in current_node.children:\n",
        "                current_node = current_node.children[split_value]\n",
        "            else:\n",
        "                # Handle the case when the split_value is not found in children\n",
        "                majority_class = Utils.find_dominating_class(current_node.target_column)\n",
        "                return majority_class\n",
        "\n",
        "        # The leaf node's class_name is the predicted target value\n",
        "        return current_node.class_name\n",
        "\n",
        "\n",
        "    #This method prints all nodes in the decision tree\n",
        "    def print_tree(self):\n",
        "\n",
        "        #Check if decision tree is empty\n",
        "        if self.root is None:\n",
        "            print(\"Decision tree is emtpy\")\n",
        "            return\n",
        "\n",
        "        #Otherwise, iterate over all nodes in the decision tree\n",
        "\n",
        "        node_queue = []\n",
        "        node_queue.append(self.root)\n",
        "\n",
        "        while node_queue:\n",
        "            current_node = node_queue.pop(0)\n",
        "            current_node.print()\n",
        "\n",
        "            for child_node in current_node.children.values():\n",
        "                node_queue.append(child_node)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2cd4e75",
      "metadata": {
        "id": "f2cd4e75"
      },
      "outputs": [],
      "source": [
        "# This function contains the code to create your decision tree\n",
        "def main():\n",
        "\n",
        "    # Read the data from csv file and store in a pandas datafrane\n",
        "    golf_dataframe = pd.read_csv(\"golf_dataset.csv\")\n",
        "\n",
        "    print(golf_dataframe)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    max_height = 6\n",
        "\n",
        "    # Generate decision tree for golf data set, target variable \"Play Golf\" and max_height=3\n",
        "    dt = DecisionTree(max_height, golf_dataframe, 'Play Golf')\n",
        "\n",
        "    # Print content of the created tree\n",
        "    #print(\"-----Tree-----\")\n",
        "    dt.print_tree()\n",
        "\n",
        "    #Run test method to predict unseen values.\n",
        "    test_decision_tree(max_height, golf_dataframe, \"Play Golf\")\n",
        "\n",
        "\n",
        "# Test the DecisionTree with the values below\n",
        "def test_decision_tree(max_height, instances, target_name):\n",
        "\n",
        "    dt = DecisionTree(max_height=3, instances=instances, target_name=target_name)\n",
        "\n",
        "    # Test values\n",
        "    parameter = {\n",
        "        'Outlook': 'Sunny',\n",
        "        'Temp': 'Cool',\n",
        "        'Humidity': 'Normal',\n",
        "        'Windy': False\n",
        "    }\n",
        "\n",
        "    print(\"Predicting to play golf with parameters:\")\n",
        "    for column, value in parameter.items():\n",
        "      print(f\"  {column}: {value}\")\n",
        "\n",
        "    # Make a prediction\n",
        "    result = dt.predict(parameter)\n",
        "\n",
        "    print(\"Prediction:\", result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8306d6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8306d6d",
        "outputId": "0c78e702-4b0e-41c2-e91f-4f37dca720ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Outlook  Temp Humidity  Windy Play Golf\n",
            "0      Rainy   Hot     High  False        No\n",
            "1      Rainy   Hot     High   True        No\n",
            "2   Overcast   Hot     High  False       Yes\n",
            "3      Sunny  Mild     High  False       Yes\n",
            "4      Sunny  Cool   Normal  False       Yes\n",
            "5      Sunny  Cool   Normal   True        No\n",
            "6   Overcast  Cool   Normal   True       Yes\n",
            "7      Rainy  Mild     High  False        No\n",
            "8      Rainy  Cool   Normal  False       Yes\n",
            "9      Sunny  Mild   Normal  False       Yes\n",
            "10     Rainy  Mild   Normal   True       Yes\n",
            "11  Overcast  Mild     High   True       Yes\n",
            "12  Overcast   Hot   Normal  False       Yes\n",
            "13     Sunny  Mild     High   True        No\n",
            "\n",
            "\n",
            "Node<1>\n",
            "  Non leaf node - Parent: None\n",
            "  Split variable: Outlook\n",
            "    Child_node: 2, split_value: Rainy\n",
            "    Child_node: 21, split_value: Overcast\n",
            "    Child_node: 37, split_value: Sunny\n",
            "Node<2>\n",
            "  Non leaf node - Parent: 1\n",
            "  Split variable: Temp\n",
            "    Child_node: 3, split_value: Mild\n",
            "    Child_node: 10, split_value: Cool\n",
            "    Child_node: 14, split_value: Hot\n",
            "Node<21>\n",
            "  Non leaf node - Parent: 1\n",
            "  Split variable: Temp\n",
            "    Child_node: 22, split_value: Mild\n",
            "    Child_node: 26, split_value: Cool\n",
            "    Child_node: 30, split_value: Hot\n",
            "Node<37>\n",
            "  Non leaf node - Parent: 1\n",
            "  Split variable: Temp\n",
            "    Child_node: 38, split_value: Mild\n",
            "    Child_node: 47, split_value: Cool\n",
            "Node<3>\n",
            "  Non leaf node - Parent: 2\n",
            "  Split variable: Humidity\n",
            "    Child_node: 4, split_value: Normal\n",
            "    Child_node: 7, split_value: High\n",
            "Node<10>\n",
            "  Non leaf node - Parent: 2\n",
            "  Split variable: Outlook\n",
            "    Child_node: 11, split_value: Rainy\n",
            "Node<14>\n",
            "  Non leaf node - Parent: 2\n",
            "  Split variable: Windy\n",
            "    Child_node: 15, split_value: False\n",
            "    Child_node: 18, split_value: True\n",
            "Node<22>\n",
            "  Non leaf node - Parent: 21\n",
            "  Split variable: Outlook\n",
            "    Child_node: 23, split_value: Overcast\n",
            "Node<26>\n",
            "  Non leaf node - Parent: 21\n",
            "  Split variable: Outlook\n",
            "    Child_node: 27, split_value: Overcast\n",
            "Node<30>\n",
            "  Non leaf node - Parent: 21\n",
            "  Split variable: Humidity\n",
            "    Child_node: 31, split_value: Normal\n",
            "    Child_node: 34, split_value: High\n",
            "Node<38>\n",
            "  Non leaf node - Parent: 37\n",
            "  Split variable: Humidity\n",
            "    Child_node: 39, split_value: Normal\n",
            "    Child_node: 42, split_value: High\n",
            "Node<47>\n",
            "  Non leaf node - Parent: 37\n",
            "  Split variable: Windy\n",
            "    Child_node: 48, split_value: False\n",
            "    Child_node: 51, split_value: True\n",
            "Node<4>\n",
            "  Non leaf node - Parent: 3\n",
            "  Split variable: Outlook\n",
            "    Child_node: 5, split_value: Rainy\n",
            "Node<7>\n",
            "  Non leaf node - Parent: 3\n",
            "  Split variable: Outlook\n",
            "    Child_node: 8, split_value: Rainy\n",
            "Node<11>\n",
            "  Non leaf node - Parent: 10\n",
            "  Split variable: Outlook\n",
            "    Child_node: 12, split_value: Rainy\n",
            "Node<15>\n",
            "  Non leaf node - Parent: 14\n",
            "  Split variable: Outlook\n",
            "    Child_node: 16, split_value: Rainy\n",
            "Node<18>\n",
            "  Non leaf node - Parent: 14\n",
            "  Split variable: Outlook\n",
            "    Child_node: 19, split_value: Rainy\n",
            "Node<23>\n",
            "  Non leaf node - Parent: 22\n",
            "  Split variable: Outlook\n",
            "    Child_node: 24, split_value: Overcast\n",
            "Node<27>\n",
            "  Non leaf node - Parent: 26\n",
            "  Split variable: Outlook\n",
            "    Child_node: 28, split_value: Overcast\n",
            "Node<31>\n",
            "  Non leaf node - Parent: 30\n",
            "  Split variable: Outlook\n",
            "    Child_node: 32, split_value: Overcast\n",
            "Node<34>\n",
            "  Non leaf node - Parent: 30\n",
            "  Split variable: Outlook\n",
            "    Child_node: 35, split_value: Overcast\n",
            "Node<39>\n",
            "  Non leaf node - Parent: 38\n",
            "  Split variable: Outlook\n",
            "    Child_node: 40, split_value: Sunny\n",
            "Node<42>\n",
            "  Non leaf node - Parent: 38\n",
            "  Split variable: Windy\n",
            "    Child_node: 43, split_value: False\n",
            "    Child_node: 45, split_value: True\n",
            "Node<48>\n",
            "  Non leaf node - Parent: 47\n",
            "  Split variable: Outlook\n",
            "    Child_node: 49, split_value: Sunny\n",
            "Node<51>\n",
            "  Non leaf node - Parent: 47\n",
            "  Split variable: Outlook\n",
            "    Child_node: 52, split_value: Sunny\n",
            "Node<5>\n",
            "  Non leaf node - Parent: 4\n",
            "  Split variable: Outlook\n",
            "    Child_node: 6, split_value: Rainy\n",
            "Node<8>\n",
            "  Non leaf node - Parent: 7\n",
            "  Split variable: Outlook\n",
            "    Child_node: 9, split_value: Rainy\n",
            "Node<12>\n",
            "  Non leaf node - Parent: 11\n",
            "  Split variable: Outlook\n",
            "    Child_node: 13, split_value: Rainy\n",
            "Node<16>\n",
            "  Non leaf node - Parent: 15\n",
            "  Split variable: Outlook\n",
            "    Child_node: 17, split_value: Rainy\n",
            "Node<19>\n",
            "  Non leaf node - Parent: 18\n",
            "  Split variable: Outlook\n",
            "    Child_node: 20, split_value: Rainy\n",
            "Node<24>\n",
            "  Non leaf node - Parent: 23\n",
            "  Split variable: Outlook\n",
            "    Child_node: 25, split_value: Overcast\n",
            "Node<28>\n",
            "  Non leaf node - Parent: 27\n",
            "  Split variable: Outlook\n",
            "    Child_node: 29, split_value: Overcast\n",
            "Node<32>\n",
            "  Non leaf node - Parent: 31\n",
            "  Split variable: Outlook\n",
            "    Child_node: 33, split_value: Overcast\n",
            "Node<35>\n",
            "  Non leaf node - Parent: 34\n",
            "  Split variable: Outlook\n",
            "    Child_node: 36, split_value: Overcast\n",
            "Node<40>\n",
            "  Non leaf node - Parent: 39\n",
            "  Split variable: Outlook\n",
            "    Child_node: 41, split_value: Sunny\n",
            "Node<43>\n",
            "  Non leaf node - Parent: 42\n",
            "  Split variable: Outlook\n",
            "    Child_node: 44, split_value: Sunny\n",
            "Node<45>\n",
            "  Non leaf node - Parent: 42\n",
            "  Split variable: Outlook\n",
            "    Child_node: 46, split_value: Sunny\n",
            "Node<49>\n",
            "  Non leaf node - Parent: 48\n",
            "  Split variable: Outlook\n",
            "    Child_node: 50, split_value: Sunny\n",
            "Node<52>\n",
            "  Non leaf node - Parent: 51\n",
            "  Split variable: Outlook\n",
            "    Child_node: 53, split_value: Sunny\n",
            "Node<6>\n",
            "  Leaf node - Parent:  5 , Decision:  ('Yes',)\n",
            "Node<9>\n",
            "  Leaf node - Parent:  8 , Decision:  ('No',)\n",
            "Node<13>\n",
            "  Leaf node - Parent:  12 , Decision:  ('Yes',)\n",
            "Node<17>\n",
            "  Leaf node - Parent:  16 , Decision:  ('No',)\n",
            "Node<20>\n",
            "  Leaf node - Parent:  19 , Decision:  ('No',)\n",
            "Node<25>\n",
            "  Leaf node - Parent:  24 , Decision:  ('Yes',)\n",
            "Node<29>\n",
            "  Leaf node - Parent:  28 , Decision:  ('Yes',)\n",
            "Node<33>\n",
            "  Leaf node - Parent:  32 , Decision:  ('Yes',)\n",
            "Node<36>\n",
            "  Leaf node - Parent:  35 , Decision:  ('Yes',)\n",
            "Node<41>\n",
            "  Leaf node - Parent:  40 , Decision:  ('Yes',)\n",
            "Node<44>\n",
            "  Leaf node - Parent:  43 , Decision:  ('Yes',)\n",
            "Node<46>\n",
            "  Leaf node - Parent:  45 , Decision:  ('No',)\n",
            "Node<50>\n",
            "  Leaf node - Parent:  49 , Decision:  ('Yes',)\n",
            "Node<53>\n",
            "  Leaf node - Parent:  52 , Decision:  ('No',)\n",
            "Predicting to play golf with parameters:\n",
            "  Outlook: Sunny\n",
            "  Temp: Cool\n",
            "  Humidity: Normal\n",
            "  Windy: False\n",
            "Prediction: ('No',)\n"
          ]
        }
      ],
      "source": [
        "# Call the main function run the code\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:da272a_ass3]",
      "language": "python",
      "name": "conda-env-da272a_ass3-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}